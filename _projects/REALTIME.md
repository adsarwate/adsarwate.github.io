---
layout: page
title: Inference and Latency in Mobile Edge Systems
description: How should we manage on-device ML/AI with edge assitance?
img: assets/img/projects/realtime.png
importance: 4
category: work
---

Deploying complex machine learning models on resource-constrained devices is
challenging due to limited computational power, memory, and model retrainabil-
ity. One proposal is to have mobile devices offload computation to processing centers which are physically closer than the abstract "cloud." These *mobile edge cloud (MEC)* systems raise a number of interesting challenges in terms of latency, accuracy, energy efficiency, and privacy (among others).

#### Representative publications

*  Yu Wu, Yansong Li, Zeyu Dong, Nitya Sathyavageeswaran, and Anand D. Sarwate, 
Learning to Help in Multi-Class Settings, 
In The Thirteenth International Conference on Learning Representations (ICLR 2025), Apr 2025. 

#### Support

This project is [funded by the NSF](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2148104&HistoricalAwards=false). We also have a [project page](https://realtime-rutgers.github.io/).